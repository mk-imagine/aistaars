{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB_Classifier:\n",
    "    def __init__(self, filename):\n",
    "        self._raw_data = self.listify_csv(filename)\n",
    "        self._class_token_count = {}\n",
    "        self._vocab = {}\n",
    "\n",
    "    def listify_csv(self, filename):\n",
    "        import csv\n",
    "        \n",
    "        with open(filename, 'r') as f:\n",
    "            templist = []\n",
    "            reader = csv.reader(f, quotechar='\"', delimiter=',',\n",
    "                quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "            for l in reader:\n",
    "                templist.append(l)\n",
    "        \n",
    "        ret_list = []\n",
    "        for text,cls in templist:\n",
    "            ret_list.append((text\n",
    "                             .replace(\",\", \"\")\n",
    "                             .replace(\".\", \"\")\n",
    "                             .replace(\"!\", \"\")\n",
    "                             .replace(\"?\", \"\")\n",
    "                             .lower()\n",
    "                             .split()\n",
    "                             , int(cls)))\n",
    "\n",
    "        return ret_list\n",
    "    \n",
    "    def train(self):\n",
    "        for text,cls in self._raw_data:\n",
    "            if cls not in self._class_token_count.keys():\n",
    "                self._class_token_count[cls] = len(text)\n",
    "                self._vocab[cls] = {}\n",
    "            else:\n",
    "                self._class_token_count[cls] += len(text)\n",
    "\n",
    "            for word in text:\n",
    "                if word in self._vocab[cls]:\n",
    "                    self._vocab[cls][word] += 1\n",
    "                else:\n",
    "                    self._vocab[cls][word] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 178, 1: 145}\n",
      "{'wow': 1, 'loved': 2, 'this': 4, 'place': 3, 'stopped': 1, 'by': 3, 'during': 1, 'the': 8, 'late': 1, 'may': 1, 'bank': 1, 'holiday': 1, 'off': 1, 'rick': 1, 'steve': 1, 'recommendation': 1, 'and': 7, 'it': 1, 'selection': 1, 'on': 1, 'menu': 2, 'was': 5, 'great': 4, 'so': 5, 'were': 2, 'prices': 2, 'fries': 1, 'too': 1, 'a': 3, 'touch': 1, 'service': 2, 'very': 1, 'prompt': 1, 'highly': 1, 'recommended': 1, 'is': 3, 'also': 1, 'cute': 1, 'best': 1, 'tacos': 1, 'in': 1, 'town': 1, 'far': 1, 'they': 2, 'performed': 1, \"that's\": 1, 'rightthe': 1, 'red': 1, 'velvet': 1, 'cakeohhh': 1, 'stuff': 1, 'good': 3, 'i': 2, 'found': 1, 'accident': 1, 'could': 1, 'not': 1, 'be': 1, 'happier': 1, 'each': 1, 'day': 1, 'of': 1, 'week': 1, 'have': 1, 'different': 1, 'deal': 1, \"it's\": 1, 'all': 2, 'delicious': 2, 'ample': 1, 'portions': 1, 'my': 2, 'first': 1, 'visit': 1, 'to': 1, 'hiro': 1, 'delight': 1, 'their': 2, 'chow': 1, 'mein': 1, 'portion': 1, 'huge': 1, 'receives': 1, 'stars': 1, 'for': 1, 'appetizers': 1, 'cocktails': 1, 'are': 1, 'handmade': 1, 'drink': 1, 'never': 1, 'empty': 1, 'he': 1, 'made': 1, 'some': 1, 'really': 1, 'suggestions': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = NB_Classifier('train.csv')\n",
    "classifier.train()\n",
    "print(classifier._class_token_count)\n",
    "print(classifier._vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc620",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
